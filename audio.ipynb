{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "\n",
    "data_dir = \"AudioWAV\"\n",
    "\n",
    "\n",
    "all_audio_files = glob(os.path.join(data_dir, \"*.wav\"))\n",
    "\n",
    "# Define emotions based on filename (CREMA-D format)\n",
    "emotion_dict = {\n",
    "    \"SAD\": 0, \"ANG\": 1, \"DIS\": 2, \"FEA\": 3, \"HAP\": 4, \"NEU\": 5\n",
    "}\n",
    "\n",
    "# Extract labels from filenames (e.g., \"1001_IEO_SAD_HI.wav\")\n",
    "data = []\n",
    "for file in all_audio_files:\n",
    "    filename = os.path.basename(file)\n",
    "    parts = filename.split(\"_\")\n",
    "    if len(parts) > 2:\n",
    "        emotion_label = emotion_dict.get(parts[2])  # Extracting emotion\n",
    "        if emotion_label is not None:\n",
    "            data.append({\"path\": file, \"emotion\": emotion_label})\n",
    "\n",
    "# Convert to a DataFrame\n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AudioWAV\\1001_DFA_ANG_XX.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AudioWAV\\1001_DFA_DIS_XX.wav</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AudioWAV\\1001_DFA_FEA_XX.wav</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AudioWAV\\1001_DFA_HAP_XX.wav</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AudioWAV\\1001_DFA_NEU_XX.wav</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7437</th>\n",
       "      <td>AudioWAV\\1091_WSI_DIS_XX.wav</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7438</th>\n",
       "      <td>AudioWAV\\1091_WSI_FEA_XX.wav</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7439</th>\n",
       "      <td>AudioWAV\\1091_WSI_HAP_XX.wav</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7440</th>\n",
       "      <td>AudioWAV\\1091_WSI_NEU_XX.wav</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7441</th>\n",
       "      <td>AudioWAV\\1091_WSI_SAD_XX.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7442 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              path  emotion\n",
       "0     AudioWAV\\1001_DFA_ANG_XX.wav        1\n",
       "1     AudioWAV\\1001_DFA_DIS_XX.wav        2\n",
       "2     AudioWAV\\1001_DFA_FEA_XX.wav        3\n",
       "3     AudioWAV\\1001_DFA_HAP_XX.wav        4\n",
       "4     AudioWAV\\1001_DFA_NEU_XX.wav        5\n",
       "...                            ...      ...\n",
       "7437  AudioWAV\\1091_WSI_DIS_XX.wav        2\n",
       "7438  AudioWAV\\1091_WSI_FEA_XX.wav        3\n",
       "7439  AudioWAV\\1091_WSI_HAP_XX.wav        4\n",
       "7440  AudioWAV\\1091_WSI_NEU_XX.wav        5\n",
       "7441  AudioWAV\\1091_WSI_SAD_XX.wav        0\n",
       "\n",
       "[7442 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.50.3)\n",
      "Collecting datasets\n",
      "  Using cached datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: librosa in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.10.1)\n",
      "Requirement already satisfied: soundfile in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.12.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\tanaz\\appdata\\roaming\\python\\python310\\site-packages (from transformers) (3.11.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.30.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\tanaz\\appdata\\roaming\\python\\python310\\site-packages (from datasets) (2.0.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (3.11.14)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (1.4.1.post1)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (1.3.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (4.4.2)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (0.59.1)\n",
      "Requirement already satisfied: pooch>=1.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (1.8.1)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (0.3.7)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (4.12.2)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (1.0.8)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from soundfile) (1.15.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cffi>=1.0->soundfile) (2.21)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from numba>=0.51.0->librosa) (0.42.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\tanaz\\appdata\\roaming\\python\\python310\\site-packages (from pooch>=1.0->librosa) (3.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (3.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Using cached datasets-3.5.0-py3-none-any.whl (491 kB)\n",
      "Installing collected packages: datasets\n",
      "Successfully installed datasets-3.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.6.0+cu126)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.6.0+cu126)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.50.3-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: librosa in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.10.1)\n",
      "Requirement already satisfied: soundfile in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.12.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\tanaz\\appdata\\roaming\\python\\python310\\site-packages (from torch) (3.11.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\tanaz\\appdata\\roaming\\python\\python310\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\tanaz\\appdata\\roaming\\python\\python310\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.30.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\tanaz\\appdata\\roaming\\python\\python310\\site-packages (from datasets) (2.0.0)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (3.11.14)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (1.4.1.post1)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (1.3.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (4.4.2)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (0.59.1)\n",
      "Requirement already satisfied: pooch>=1.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (1.8.1)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (0.3.7)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from librosa) (1.0.8)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from soundfile) (1.15.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cffi>=1.0->soundfile) (2.21)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from numba>=0.51.0->librosa) (0.42.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\tanaz\\appdata\\roaming\\python\\python310\\site-packages (from pooch>=1.0->librosa) (3.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (3.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading transformers-4.50.3-py3-none-any.whl (10.2 MB)\n",
      "   ---------------------------------------- 0.0/10.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/10.2 MB 5.3 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.5/10.2 MB 8.0 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.8/10.2 MB 8.5 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.9/10.2 MB 5.8 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.7/10.2 MB 9.2 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.2/10.2 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.6/10.2 MB 9.7 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.0/10.2 MB 9.6 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.5/10.2 MB 9.6 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 3.9/10.2 MB 10.0 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 4.4/10.2 MB 10.0 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 4.9/10.2 MB 10.1 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 5.4/10.2 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 5.8/10.2 MB 10.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 6.2/10.2 MB 10.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 6.7/10.2 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.1/10.2 MB 10.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 7.6/10.2 MB 10.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.0/10.2 MB 10.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.3/10.2 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.8/10.2 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.3/10.2 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.6/10.2 MB 10.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.6/10.2 MB 10.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.7/10.2 MB 10.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.9/10.2 MB 9.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.0/10.2 MB 9.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.2/10.2 MB 9.2 MB/s eta 0:00:00\n",
      "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
      "   ---------------------------------------- 0.0/491.2 kB ? eta -:--:--\n",
      "   ------------------ --------------------- 225.3/491.2 kB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 491.2/491.2 kB 6.2 MB/s eta 0:00:00\n",
      "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "   ---------------------------------------- 0.0/134.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 134.8/134.8 kB 4.0 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.5/2.4 MB 10.0 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.8/2.4 MB 10.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.3/2.4 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.6/2.4 MB 9.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.0/2.4 MB 9.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.4/2.4 MB 9.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 8.6 MB/s eta 0:00:00\n",
      "Downloading xxhash-3.5.0-cp310-cp310-win_amd64.whl (30 kB)\n",
      "Installing collected packages: xxhash, multiprocess, tokenizers, transformers, datasets\n",
      "Successfully installed datasets-3.5.0 multiprocess-0.70.16 tokenizers-0.21.1 transformers-4.50.3 xxhash-3.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets librosa soundfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "def load_audio(examples):\n",
    "    audio, sr = librosa.load(examples, sr=16000)  \n",
    "    return audio\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tanaz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\configuration_utils.py:315: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import Wav2Vec2FeatureExtractor, Wav2Vec2ForSequenceClassification\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_name = \"facebook/wav2vec2-base\"\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(model_name)\n",
    "\n",
    "model = Wav2Vec2ForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=6,\n",
    "    label2id=emotion_dict,\n",
    "    id2label={v: k for k, v in emotion_dict.items()},\n",
    ").to(device)  # Move model to GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "373f411b30384fecbca475b228104694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7442 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tanaz\\AppData\\Local\\Temp\\ipykernel_2704\\1350064035.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"input_values\": torch.tensor(inputs[\"input_values\"].squeeze(0)),\n"
     ]
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    audio = load_audio(examples[\"path\"])\n",
    "    inputs = feature_extractor(audio, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "    return {\n",
    "        \"input_values\": torch.tensor(inputs[\"input_values\"].squeeze(0)),  \n",
    "        \"labels\": torch.tensor(examples[\"emotion\"], dtype=torch.int32) \n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# Apply preprocessing\n",
    "dataset = dataset.map(preprocess_function,remove_columns=[\"path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = dataset.train_test_split(test_size=0.2)\n",
    "train_dataset = train_test[\"train\"]\n",
    "test_dataset = train_test[\"test\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.50.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\tanaz\\appdata\\roaming\\python\\python310\\site-packages (from transformers[torch]) (3.11.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers[torch]) (0.30.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers[torch]) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers[torch]) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers[torch]) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers[torch]) (2024.7.24)\n",
      "Requirement already satisfied: requests in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers[torch]) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers[torch]) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers[torch]) (4.67.1)\n",
      "Requirement already satisfied: torch>=2.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers[torch]) (2.6.0+cu126)\n",
      "Collecting accelerate>=0.26.0 (from transformers[torch])\n",
      "  Downloading accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: psutil in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from accelerate>=0.26.0->transformers[torch]) (5.9.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers[torch]) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers[torch]) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\tanaz\\appdata\\roaming\\python\\python310\\site-packages (from torch>=2.0->transformers[torch]) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\tanaz\\appdata\\roaming\\python\\python310\\site-packages (from torch>=2.0->transformers[torch]) (3.1.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=2.0->transformers[torch]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy==1.13.1->torch>=2.0->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers[torch]) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers[torch]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers[torch]) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers[torch]) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch>=2.0->transformers[torch]) (2.1.2)\n",
      "Downloading accelerate-1.6.0-py3-none-any.whl (354 kB)\n",
      "   ---------------------------------------- 0.0/354.7 kB ? eta -:--:--\n",
      "   ------------------------- -------------- 225.3/354.7 kB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 354.7/354.7 kB 5.6 MB/s eta 0:00:00\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-1.6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from accelerate) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from accelerate) (2.6.0+cu126)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from accelerate) (0.30.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\tanaz\\appdata\\roaming\\python\\python310\\site-packages (from huggingface-hub>=0.21.0->accelerate) (3.11.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\n",
      "Requirement already satisfied: requests in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\tanaz\\appdata\\roaming\\python\\python310\\site-packages (from torch>=2.0.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\tanaz\\appdata\\roaming\\python\\python310\\site-packages (from torch>=2.0.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tanaz\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.6.0+cu126\n",
      "Transformers version: 4.50.3\n",
      "Using device: GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"Transformers version:\", transformers.__version__)\n",
    "print(\"Using device:\", \"GPU\" if torch.cuda.is_available() else \"CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tanaz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = predictions.argmax(axis=-1)  \n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    return {\"accuracy\": accuracy}\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./wav2vec2-emotion\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2,\n",
    "    fp16=True,  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tanaz\\AppData\\Local\\Temp\\ipykernel_2704\\225571421.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=feature_extractor,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\"nll_loss_forward_reduce_cuda_kernel_2d_index\" not implemented for 'Int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Tanaz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\trainer.py:2245\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2243\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2246\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2250\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Tanaz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\trainer.py:2556\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2549\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2550\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m   2551\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2552\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[0;32m   2553\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[0;32m   2554\u001b[0m )\n\u001b[0;32m   2555\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m-> 2556\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2559\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2560\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2561\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2562\u001b[0m ):\n\u001b[0;32m   2563\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2564\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32mc:\\Users\\Tanaz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\trainer.py:3718\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[0;32m   3715\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   3717\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 3718\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3720\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[0;32m   3721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   3722\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3723\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   3724\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\Tanaz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\trainer.py:3783\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[0;32m   3781\u001b[0m         loss_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_items_in_batch\n\u001b[0;32m   3782\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloss_kwargs}\n\u001b[1;32m-> 3783\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m   3784\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[0;32m   3785\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[0;32m   3786\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Tanaz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Tanaz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Tanaz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\accelerate\\utils\\operations.py:814\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Tanaz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\accelerate\\utils\\operations.py:802\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[1;32mc:\\Users\\Tanaz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\amp\\autocast_mode.py:44\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[1;32m---> 44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Tanaz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\wav2vec2\\modeling_wav2vec2.py:2387\u001b[0m, in \u001b[0;36mWav2Vec2ForSequenceClassification.forward\u001b[1;34m(self, input_values, attention_mask, output_attentions, output_hidden_states, return_dict, labels)\u001b[0m\n\u001b[0;32m   2385\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2386\u001b[0m     loss_fct \u001b[38;5;241m=\u001b[39m CrossEntropyLoss()\n\u001b[1;32m-> 2387\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[0;32m   2390\u001b[0m     output \u001b[38;5;241m=\u001b[39m (logits,) \u001b[38;5;241m+\u001b[39m outputs[_HIDDEN_STATES_START_POSITION:]\n",
      "File \u001b[1;32mc:\\Users\\Tanaz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Tanaz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Tanaz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1295\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Tanaz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:3494\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3493\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3494\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3495\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3501\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: \"nll_loss_forward_reduce_cuda_kernel_2d_index\" not implemented for 'Int'"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
